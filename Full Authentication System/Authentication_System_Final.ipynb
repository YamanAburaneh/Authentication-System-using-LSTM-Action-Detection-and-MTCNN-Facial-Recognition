{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using webcam recognize face\n",
    "import torch\n",
    "import pyttsx3\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from torchvision import datasets\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "from gtts import gTTS\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from scipy import stats\n",
    "\n",
    "import serial\n",
    "import time\n",
    "import winsound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abcc8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9fa2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "def Vname(namel):\n",
    "    engine = pyttsx3.init()\n",
    "    rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "    engine.setProperty('rate', 125)     # setting up new voice rate\n",
    "    voices = engine.getProperty('voices')       #getting details of current voice\n",
    "    #engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "    engine.setProperty('voice', voices[1].id)   #changing index, changes voices. 1 for female\n",
    "    volume = engine.getProperty('volume')   #getting to know current volume level (min=0 and max=1)\n",
    "    engine.setProperty('volume',1.0)    # setting up volume level  between 0 and 1\n",
    "\n",
    "    text = \"Welcome\" + namel\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "############### \n",
    "\n",
    "# initializing MTCNN and InceptionResnetV1 \n",
    "mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) # keep_all=False if multiple faces keep all false and detect one only\n",
    "mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) # keep_all=True to keep all faces in form of list\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()  # using vggface2 pretrained model \n",
    "\n",
    "# # Read data from folder\n",
    "\n",
    "# loading data.pt file\n",
    "load_data = torch.load('data.pt') \n",
    "embedding_list = load_data[0] \n",
    "name_list = load_data[1] \n",
    "\n",
    "\n",
    "\n",
    "def face():\n",
    "    current_name = None\n",
    "    counter_dakhel = 0\n",
    "    counter_yaman = 0\n",
    "    counter_mohammed = 0\n",
    "    namev = 0 \n",
    "    n = 8\n",
    "    namel = \"\"\n",
    "\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            print(\"fail to grab frame, try again\")\n",
    "            break\n",
    "\n",
    "        img = Image.fromarray(frame)\n",
    "        img_cropped_list, prob_list = mtcnn(img, return_prob=True) \n",
    "\n",
    "        if img_cropped_list is not None:\n",
    "            boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "            for i, prob in enumerate(prob_list):\n",
    "                if prob>0.90:\n",
    "                    emb = resnet(img_cropped_list[i].unsqueeze(0)).detach() \n",
    "\n",
    "                    dist_list = [] # list of matched distances, minimum distance is used to identify the person\n",
    "\n",
    "                    for idx, emb_db in enumerate(embedding_list):\n",
    "                        dist = torch.dist(emb, emb_db).item()\n",
    "                        dist_list.append(dist)\n",
    "\n",
    "                    min_dist = min(dist_list) # get minumum dist value\n",
    "                    min_dist_idx = dist_list.index(min_dist) # get minumum dist index\n",
    "                    name = name_list[min_dist_idx] # get name corrosponding to minimum dist\n",
    "\n",
    "                    box = boxes[i] \n",
    "\n",
    "                    original_frame = frame.copy() # storing copy of frame before drawing on it\n",
    "\n",
    "\n",
    "                    if min_dist < 0.90:\n",
    "                        namel = name\n",
    "                        if current_name != namel:\n",
    "                            current_name = namel\n",
    "                            counter_dakhel = 0\n",
    "                            counter_yaman = 0\n",
    "                            counter_mohammed = 0\n",
    "                        if namel == \"Dakhel\":\n",
    "                            counter_dakhel += 1\n",
    "                            print(f\"Name: {namel} - Count: {counter_dakhel}\")\n",
    "                        elif namel == \"Yaman\":\n",
    "                            counter_yaman += 1\n",
    "                            print(f\"Name: {namel} - Count: {counter_yaman}\")\n",
    "                        elif namel == \"Mohammed\":\n",
    "                            counter_mohammed += 1\n",
    "                            print(f\"Name: {namel} - Count: {counter_mohammed}\")\n",
    "\n",
    "\n",
    "\n",
    "#         cv2.imshow(\"IMG\", frame)\n",
    "\n",
    "\n",
    "        k = cv2.waitKey(1)\n",
    "        if k%256==27: # ESC\n",
    "            print('Esc pressed, closing...')\n",
    "            break\n",
    "        \n",
    "        xp = 330\n",
    "        yp = 225\n",
    "        \n",
    "        if counter_dakhel == n:\n",
    "            namev=1        \n",
    "            print(\"Welcome :\" + namel + \"- Name Index : \" + str(namev))\n",
    "            Vname(namel)\n",
    "            break\n",
    "        \n",
    "        if counter_mohammed == n:\n",
    "            namev=2\n",
    "            print(\"Welcome :\" + namel + \"- Name Index : \" + str(namev)) \n",
    "            Vname(namel)\n",
    "            break\n",
    "\n",
    "        if counter_yaman == n:\n",
    "            namev=3\n",
    "            print(\"Welcome :\" + namel + \" - Name Index : \" + str(namev)) \n",
    "            Vname(namel)\n",
    "            break\n",
    "#     vid.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "    return namel\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12061849",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(120,120,120), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(1,1,1), thickness=2, circle_radius=2))\n",
    "def extract_keypoints(results):\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([rh])\n",
    "\n",
    "##############\n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['zero', 'one', 'two', 'three', 'four', 'five'])\n",
    "\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, activation='relu', input_shape=(30,63)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "model.load_weights('actionDetection.h5')\n",
    "\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signM():\n",
    "\n",
    "    # Text to Speech Module\n",
    "    engine = pyttsx3.init()\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[1].id)\n",
    "    volume = engine.getProperty('volume')\n",
    "    engine.setProperty('volume',1.0)\n",
    "    rate = engine.getProperty('rate')\n",
    "    engine.setProperty('rate', 125) \n",
    "    \n",
    "    # 1. New detection variables\n",
    "    sequence = []\n",
    "    sentence = []\n",
    "    predictions = []\n",
    "    threshold = 0.7\n",
    "\n",
    "#     vid = cv2.VideoCapture(0)\n",
    "\n",
    "    # Set mediapipe model \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while vid.isOpened():\n",
    "\n",
    "            # Read feed\n",
    "            ret, frame = vid.read()\n",
    "\n",
    "            # Make detections\n",
    "            global image1\n",
    "            \n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "            # Draw landmarks\n",
    "            draw_landmarks(image, results)\n",
    "\n",
    "            # 2. Prediction logic\n",
    "            keypoints = extract_keypoints(results)\n",
    "            sequence.append(keypoints)\n",
    "            sequence = sequence[-30:]\n",
    "\n",
    "            if len(sequence) == 30:\n",
    "                res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                predictions.append(np.argmax(res))\n",
    "\n",
    "            #3. Viz logic\n",
    "                if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                    if res[np.argmax(res)] > threshold: \n",
    "\n",
    "                        if len(sentence) > 0: \n",
    "                            if actions[np.argmax(res)] != sentence[-1]:\n",
    "                                sentence.append(actions[np.argmax(res)])\n",
    "                        else:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "                if len(sentence) > 10: \n",
    "                    sentence = sentence[-10:]\n",
    "\n",
    "            cv2.rectangle(image, (0,0), (640, 40), (0, 0, 0), -1)\n",
    "            cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Authentication\n",
    "            if len(sentence) == 4:\n",
    "                time.sleep(2)\n",
    "\n",
    "                break\n",
    "                \n",
    "            image1= image\n",
    "            \n",
    "            # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', image1)\n",
    "\n",
    "\n",
    "            # Break gracefully\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "#         vid.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ec2ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a video capture object\n",
    "# Create a GUI app\n",
    "\n",
    "tColor = \"black\"\n",
    "pFont = \"Cascadia Code\"\n",
    "app = Tk()\n",
    "\n",
    "app.geometry(\"666x620\")\n",
    "\n",
    "# Bind the app with Escape keyboard to\n",
    "# quit app whenever pressed\n",
    "app.bind('<Escape>', lambda e: app.quit())\n",
    "\n",
    "# Create a label and display it on app\n",
    "label_widget = Label(app)\n",
    "# app[\"bg\"] = \"#252526\"\n",
    "\n",
    "label_widget.pack()\n",
    "app.title(\"Authentication System\")\n",
    "\n",
    "###################\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "engine.setProperty('rate', 125)     # setting up new voice rate\n",
    "voices = engine.getProperty('voices')       #getting details of current voice\n",
    "#engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "engine.setProperty('voice', voices[1].id)   #changing index, changes voices. 1 for female\n",
    "volume = engine.getProperty('volume')   #getting to know current volume level (min=0 and max=1)\n",
    "engine.setProperty('volume',1.0)    # setting up volume level  between 0 and 1\n",
    "\n",
    "ser = serial.Serial('COM16', 9600)  # Replace 'COM3' with the serial port used by your Arduino\n",
    "\n",
    "def arduino():\n",
    "    ser.write(b'H')\n",
    "    ser.close()\n",
    "    time.sleep(5)\n",
    "    ser.open()\n",
    "\n",
    "\n",
    "global vid\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# Declare the width and height in variables\n",
    "width, height = 600, 600\n",
    "\n",
    "# Set the width and height\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "# Create a canvas to display the camera feed\n",
    "global canvas\n",
    "canvas = Canvas(app, width=850, height=600)\n",
    "canvas.place(x=10, y=60)\n",
    "\n",
    "namex = 10\n",
    "namey = 10\n",
    "text_ni = Label(app, text=\"Name :\" + \" \"  ,fg=tColor, font=(pFont, 10))\n",
    "text_ni.place(x=namex,y=namey)\n",
    "\n",
    "passx = 10\n",
    "passy = 30\n",
    "text_pi = Label(app, text=\"Entered Passwored :\" + \" \"  ,fg=tColor, font=(pFont, 10))\n",
    "text_pi.place(x=passx,y=passy)\n",
    "\n",
    "\n",
    "line_pi = Label(app, text=\"|\"  ,fg=\"gray\", font=(pFont, 30))\n",
    "line_pi.place(x=410,y=2)\n",
    "\n",
    "statusx = 435\n",
    "statusy = 10\n",
    "status_pi = Label(app, text=\"Status : \"  ,fg=tColor, font=(pFont, 10))\n",
    "status_pi.place(x=statusx,y=statusy)\n",
    "\n",
    "\n",
    "def Access_Granted():\n",
    "    status_p1 = Label(app, text=\"Status : \" + \"Access Granted\" ,fg=\"green\", font=(pFont, 10))\n",
    "    status_p1.place(x=statusx,y=statusy)\n",
    "    engine.say(\"Access Granted , Door opening \")\n",
    "    engine.runAndWait()\n",
    "    engine.stop()\n",
    "    winsound.Beep(2637,600)\n",
    "\n",
    "    ser.write(b'H')\n",
    "    ser.close()\n",
    "    time.sleep(6)\n",
    "    ser.open()\n",
    "\n",
    "    \n",
    "def Access_Denied():\n",
    "    status_p2 = Label(app, text=\"Status : \" + \"Access Denied\" ,fg=\"red\", font=(pFont, 10))\n",
    "    status_p2.place(x=statusx,y=statusy)\n",
    "    \n",
    "    engine.say(\"Access Denied, please try again\")\n",
    "    engine.runAndWait()\n",
    "    engine.stop()\n",
    "\n",
    "\n",
    "def action1():\n",
    "    global namef\n",
    "    namef = face()\n",
    "    \n",
    "    text_n = Label(app, text=\"Name :\" + \" \"+ namef ,fg=tColor, font=(pFont, 10))\n",
    "    text_n.place(x=namex,y=namey)\n",
    "\n",
    "    #     text_w = Label(app, text=\"Welcome\" + \" \" +namef,fg=tColor, font=(pFont, 20))\n",
    "    #     text_w.place(x=x_text_w,y=y_text_w)\n",
    "\n",
    "\n",
    "def action2():\n",
    "\n",
    "    global takenpass\n",
    "    takenpass = signM()\n",
    "    takenpassT = \"[ \" + takenpass[0] + \" , \" + takenpass[1] + \" , \" + takenpass[2] + \" , \" + takenpass[3] + \" ]\" \n",
    "    \n",
    "    text_p2 = Label(app, text=\"                                            \"  ,fg=tColor, font=(pFont, 10))\n",
    "    text_p2.place(x=passx,y=passy)\n",
    "    \n",
    "    text_p = Label(app, text=\"Entered Passwored :\" + \" \" + takenpassT ,fg=tColor, font=(pFont, 10))\n",
    "    text_p.place(x=passx,y=passy)\n",
    "    \n",
    "    if namef == \"Dakhel\" and takenpass ==  ['one', 'four', 'two', 'one']:\n",
    "        Access_Granted()     \n",
    "    elif namef == \"Yaman\" and takenpass ==  ['five', 'three', 'one', 'zero']:\n",
    "        Access_Granted()\n",
    "    elif namef == \"Mohammed\" and takenpass ==  ['four', 'zero', 'one', 'five']:\n",
    "        Access_Granted()\n",
    "    else :\n",
    "        Access_Denied()\n",
    "\n",
    "\n",
    "# Create a button to open the camera in GUI app\n",
    "button1 = Button(app, text=\"Face Detection\" , fg=tColor, font=(pFont, 20), activebackground=\"light blue\", height=1, width=19, command=action1)\n",
    "button1.place(x=10,y=550)\n",
    "\n",
    "button2 = Button(app, text=\"Sign Password\" , fg=tColor, font=(pFont, 20), activebackground=\"light blue\", height=1, width=19, command=action2)\n",
    "button2.place(x=340,y=550)\n",
    "\n",
    "\n",
    "# Start the camera feed\n",
    "while True:\n",
    "    global ret\n",
    "    global frame\n",
    "    \n",
    "    ret, frame = vid.read()\n",
    "    if ret:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(frame)\n",
    "        image = ImageTk.PhotoImage(image)\n",
    "        canvas.create_image(0, 0, image=image, anchor=NW)\n",
    "    app.update()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "               \n",
    "text_w = Label(app, text=\"Welcome\" + \" \" +namef,fg=tColor, font=(pFont, 20))\n",
    "text_w.place(x=x_text_w,y=y_text_w)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec2ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import serial\n",
    "# import time\n",
    "\n",
    "\n",
    "# ser = serial.Serial('COM16', 9600)  # Replace 'COM3' with the serial port used by your Arduino\n",
    "\n",
    "\n",
    "# # def arduino():\n",
    "# #     ser.write(b'H')\n",
    "# #     ser.close()\n",
    "# # #     time.sleep(5)\n",
    "# #     ser.open()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ser.write(b'H')\n",
    "# ser.close()\n",
    "# time.sleep(3)\n",
    "# ser.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcced37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1800b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
